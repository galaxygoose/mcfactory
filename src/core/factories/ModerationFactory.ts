// This file is generated by the Architect Agent.
// Other agents must implement logic INSIDE this file only.
// Do NOT create or delete files. Respect the MIC + MIM.

import {
  Factory,
  ModerationInput,
  ModerationResult,
  FactoryOptions,
  ProviderRequest,
  ProviderResponse
} from '../../types';
import { ProviderRegistry } from '../providers/providerRegistry';

export class ModerationFactory implements Factory<ModerationInput, ModerationResult> {
  async run(input: ModerationInput, options?: FactoryOptions): Promise<ModerationResult> {
    const providerName = options?.provider || 'openai';
    const provider = ProviderRegistry.get(providerName);

    if (!provider) {
      throw new Error(`Provider ${providerName} not found`);
    }

    const prompt = this.buildModerationPrompt(input);

    const request: ProviderRequest = {
      model: 'gpt-4',
      input: prompt,
      options: {
        temperature: 0.1,
        max_tokens: 300,
        ...options?.metadata
      }
    };

    const response: ProviderResponse = await provider.callModel(request);

    return this.parseModerationResponse(response);
  }

  private buildModerationPrompt(input: ModerationInput): string {
    return `Analyze the following text for content that may violate safety guidelines or contain inappropriate material. Categorize any issues found and provide a safety assessment.

Text to moderate:
"${input.text}"

Respond in JSON format with the following structure:
{
  "safe": boolean,
  "categories": ["category1", "category2"],
  "confidence": number,
  "flagged": boolean
}

Categories may include: hate_speech, violence, sexual_content, harassment, spam, misinformation, etc.`;
  }

  private parseModerationResponse(response: ProviderResponse): ModerationResult {
    try {
      const result = typeof response.output === 'string'
        ? JSON.parse(response.output)
        : response.output;

      return {
        safe: result.safe !== false, // Default to safe if not specified
        categories: Array.isArray(result.categories) ? result.categories : [],
        confidence: typeof result.confidence === 'number' ? result.confidence : 0.5,
        flagged: result.flagged === true
      };
    } catch (error) {
      // Fallback parsing for non-JSON responses
      const output = typeof response.output === 'string' ? response.output.toLowerCase() : '';

      const flagged = output.includes('unsafe') || output.includes('inappropriate') ||
                     output.includes('violation') || output.includes('hate') ||
                     output.includes('violence') || output.includes('sexual');

      return {
        safe: !flagged,
        categories: flagged ? ['potentially_harmful'] : [],
        confidence: flagged ? 0.8 : 0.2,
        flagged
      };
    }
  }
}
