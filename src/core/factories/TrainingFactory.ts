// This file is generated by the Architect Agent.
// Other agents must implement logic INSIDE this file only.
// Do NOT create or delete files. Respect the MIC + MIM.

import {
  Factory,
  TrainingExample,
  DatasetBundle,
  TrainingExportConfig,
  FactoryOptions
} from '../../types';

export class TrainingFactory implements Factory<TrainingExample[], DatasetBundle> {
  async run(examples: TrainingExample[], options?: FactoryOptions): Promise<DatasetBundle> {
    const config = this.extractTrainingConfig(options);

    // Validate examples
    this.validateExamples(examples);

    // Process examples based on format
    const processedData = await this.processExamples(examples, config);

    // Create manifest
    const manifest = this.createManifest(examples, config);

    // Generate files
    const files = await this.generateFiles(processedData, config);


    return {
      manifest,
      files
    };
  }

  private extractTrainingConfig(options?: FactoryOptions): TrainingExportConfig {
    const metadata = options?.metadata || {};

    return {
      format: metadata.format || 'jsonl',
      shardSize: metadata.shardSize || 1000,
      schedule: metadata.schedule || 'manual',
      outputDir: metadata.outputDir || './datasets'
    };
  }

  private validateExamples(examples: TrainingExample[]): void {
    if (!Array.isArray(examples) || examples.length === 0) {
      throw new Error('Training examples must be a non-empty array');
    }

    for (const example of examples) {
      if (!example.input || typeof example.input !== 'string') {
        throw new Error('Each training example must have a valid input string');
      }
      if (!example.task || typeof example.task !== 'string') {
        throw new Error('Each training example must have a valid task string');
      }
    }
  }

  private async processExamples(examples: TrainingExample[], config: TrainingExportConfig): Promise<any> {
    switch (config.format) {
      case 'jsonl':
        return this.convertToJSONL(examples);
      case 'csv':
        return this.convertToCSV(examples);
      case 'parquet':
        return this.convertToParquet(examples);
      case 'hf':
        return this.convertToHuggingFace(examples);
      default:
        throw new Error(`Unsupported format: ${config.format}`);
    }
  }

  private convertToJSONL(examples: TrainingExample[]): string[] {
    return examples.map(example => JSON.stringify(example));
  }

  private convertToCSV(examples: TrainingExample[]): string {
    if (examples.length === 0) return '';

    // Get all unique keys from examples
    const allKeys = new Set<string>();
    examples.forEach(example => {
      Object.keys(example).forEach(key => allKeys.add(key));
      if (example.metadata) {
        Object.keys(example.metadata).forEach(key => allKeys.add(`metadata.${key}`));
      }
    });

    const headers = Array.from(allKeys);
    const csvRows = [headers.join(',')];

    examples.forEach(example => {
      const row = headers.map(header => {
        if (header.startsWith('metadata.')) {
          const metaKey = header.substring(9);
          return JSON.stringify(example.metadata?.[metaKey] || '');
        }
        const value = (example as any)[header];
        return typeof value === 'object' ? JSON.stringify(value) : value || '';
      });
      csvRows.push(row.join(','));
    });

    return csvRows.join('\n');
  }

  private convertToParquet(examples: TrainingExample[]): any {
    // Simplified implementation - in practice, would use a parquet library
    // For now, return JSON representation that could be converted to parquet
    return {
      schema: this.inferSchema(examples),
      data: examples
    };
  }

  private convertToHuggingFace(examples: TrainingExample[]): any {
    // Convert to Hugging Face dataset format
    return {
      type: 'dataset',
      format: 'json',
      data: examples.map(example => ({
        instruction: example.input,
        output: example.output || '',
        task: example.task,
        ...example.metadata
      }))
    };
  }

  private inferSchema(examples: TrainingExample[]): any {
    const schema: any = {};

    examples.forEach(example => {
      Object.entries(example).forEach(([key, value]) => {
        if (!schema[key]) {
          schema[key] = typeof value;
        }
      });
    });

    return schema;
  }

  private createManifest(examples: TrainingExample[], config: TrainingExportConfig): Record<string, any> {
    const tasks = [...new Set(examples.map(ex => ex.task))];
    const totalExamples = examples.length;
    const avgInputLength = examples.reduce((sum, ex) => sum + ex.input.length, 0) / examples.length;

    return {
      version: '1.0.0',
      format: config.format,
      created: new Date().toISOString(),
      statistics: {
        totalExamples,
        tasks,
        avgInputLength: Math.round(avgInputLength),
        hasOutputs: examples.some(ex => ex.output)
      },
      config
    };
  }

  private async generateFiles(processedData: any, config: TrainingExportConfig): Promise<string[]> {
    const files: string[] = [];
    const timestamp = Date.now();

    try {
      // For now, simulate file generation - in a real implementation, would write to disk
      // Since we're in a factory context, we return file metadata instead of actual files

      if (config.format === 'jsonl') {
        const jsonlData = processedData as string[];
        const shardSize = config.shardSize || 1000;

        // Split into shards if needed
        for (let i = 0; i < jsonlData.length; i += shardSize) {
          const shardIndex = Math.floor(i / shardSize);
          const filename = `dataset_${timestamp}_shard_${shardIndex}.jsonl`;
          files.push(filename);
        }
      } else if (config.format === 'csv') {
        const filename = `dataset_${timestamp}.csv`;
        files.push(filename);
      } else {
        // For other formats
        const filename = `dataset_${timestamp}.${config.format}`;
        files.push(filename);
      }

      // Create manifest file
      const manifestFilename = `manifest_${timestamp}.json`;
      files.push(manifestFilename);

    } catch (error) {
      console.error('Error generating training files:', error);
      throw new Error(`Failed to generate training dataset files: ${error}`);
    }

    return files;
  }
}
