// This file is generated by the Architect Agent.
// Other agents must implement logic INSIDE this file only.
// Do NOT create or delete files. Respect the MIC + MIM.

import { TrainingExample, EmbeddingRequest, ProviderRequest } from '../../types';
import { ProviderRegistry } from '../providers/providerRegistry';

/**
 * Configuration for embedding generation
 */
export interface EmbeddingConfig {
  provider?: string; // "openai", "cohere", etc.
  model?: string; // Specific model to use
  batchSize?: number; // Number of texts to process in each batch
  maxRetries?: number; // Maximum number of retries on failure
  retryDelay?: number; // Delay between retries in milliseconds
  fields?: ('input' | 'output')[]; // Which fields to embed
}

/**
 * Result of embedding generation
 */
export interface EmbeddingResult {
  embeddings: number[][];
  dimensions: number;
  successCount: number;
  failureCount: number;
  errors: string[];
  metadata: {
    provider: string;
    model: string;
    totalProcessed: number;
    processingTime: number;
  };
}

/**
 * Generates embeddings for training data using configured providers
 * Supports batching, retries, and embedding multiple fields per example
 */
export async function generateEmbeddings(
  texts: string[],
  config: EmbeddingConfig = {}
): Promise<number[][]> {
  const result = await generateEmbeddingsWithMetadata(texts, config);
  return result.embeddings;
}

/**
 * Generates embeddings for training examples, embedding specified fields
 */
export async function generateEmbeddingsForExamples(
  examples: TrainingExample[],
  config: EmbeddingConfig = {}
): Promise<EmbeddingResult> {
  const {
    fields = ['input'],
    batchSize = 10,
    maxRetries = 3,
    retryDelay = 1000,
    provider = 'openai',
    model
  } = config;

  const startTime = Date.now();
  const allTexts: string[] = [];
  const textToExampleMap: number[] = [];

  // Collect all texts to embed
  examples.forEach((example, exampleIndex) => {
    fields.forEach(field => {
      if (field === 'input' && example.input) {
        allTexts.push(example.input);
        textToExampleMap.push(exampleIndex);
      } else if (field === 'output' && example.output) {
        allTexts.push(example.output);
        textToExampleMap.push(exampleIndex);
      }
    });
  });

  if (allTexts.length === 0) {
    return {
      embeddings: [],
      dimensions: 0,
      successCount: 0,
      failureCount: 0,
      errors: ['No texts found to embed'],
      metadata: {
        provider,
        model: model || 'unknown',
        totalProcessed: 0,
        processingTime: Date.now() - startTime
      }
    };
  }

  // Generate embeddings for all texts
  const result = await generateEmbeddingsWithMetadata(allTexts, {
    batchSize,
    maxRetries,
    retryDelay,
    provider,
    model
  });

  // Attach embeddings back to examples
  let textIndex = 0;
  examples.forEach(example => {
    if (!example.metadata) {
      example.metadata = {};
    }

    fields.forEach(field => {
      if ((field === 'input' && example.input) || (field === 'output' && example.output)) {
        const embedding = result.embeddings[textIndex];
        if (embedding && embedding.length > 0 && example.metadata) {
          example.metadata[`${field}_embedding`] = embedding;
        }
        textIndex++;
      }
    });
  });

  return {
    ...result,
    metadata: {
      ...result.metadata,
      processingTime: Date.now() - startTime
    }
  };
}

/**
 * Generates embeddings with full metadata and error handling
 */
async function generateEmbeddingsWithMetadata(
  texts: string[],
  config: EmbeddingConfig = {}
): Promise<EmbeddingResult> {
  const {
    batchSize = 10,
    maxRetries = 3,
    retryDelay = 1000,
    provider = 'openai',
    model
  } = config;

  const startTime = Date.now();
  const embeddings: number[][] = [];
  const errors: string[] = [];
  let successCount = 0;
  let failureCount = 0;
  let dimensions = 0;

  // Get the embedding provider
  const embeddingProvider = ProviderRegistry.get(provider);
  if (!embeddingProvider) {
    throw new Error(`Embedding provider '${provider}' not found. Please ensure the provider is registered.`);
  }

  // Process texts in batches
  for (let i = 0; i < texts.length; i += batchSize) {
    const batch = texts.slice(i, i + batchSize);
    const batchResults = await processBatch(batch, embeddingProvider, {
      maxRetries,
      retryDelay,
      model
    });

    // Collect results
    batchResults.forEach(result => {
      if (result.success && result.embedding) {
        embeddings.push(result.embedding);
        successCount++;
        if (dimensions === 0) {
          dimensions = result.embedding.length;
        }
      } else {
        embeddings.push([]); // Placeholder for failed embedding
        failureCount++;
        if (result.error) {
          errors.push(result.error);
        }
      }
    });
  }

  return {
    embeddings,
    dimensions,
    successCount,
    failureCount,
    errors,
    metadata: {
      provider,
      model: model || 'default',
      totalProcessed: texts.length,
      processingTime: Date.now() - startTime
    }
  };
}

/**
 * Processes a batch of texts for embedding
 */
async function processBatch(
  texts: string[],
  provider: any,
  options: { maxRetries: number; retryDelay: number; model?: string }
): Promise<Array<{ success: boolean; embedding?: number[]; error?: string }>> {
  const results: Array<{ success: boolean; embedding?: number[]; error?: string }> = [];

  // For now, process texts individually since the embedding provider expects single texts
  // In a real implementation, you might batch multiple texts per API call if supported
  for (const text of texts) {
    let success = false;
    let embedding: number[] | undefined;
    let error: string | undefined;

    for (let attempt = 0; attempt <= options.maxRetries && !success; attempt++) {
      try {
        const embeddingRequest: EmbeddingRequest = {
          text: text
        };

        const request: ProviderRequest = {
          model: options.model || 'text-embedding-ada-002',
          input: embeddingRequest,
          options: {
            provider: provider.name.toLowerCase()
          }
        };

        const response = await provider.callModel(request);

        if (response.output && typeof response.output === 'object' && 'embedding' in response.output) {
          const embeddingResponse = response.output as { embedding: number[]; dimensions: number };
          embedding = embeddingResponse.embedding;
          success = true;
        } else {
          throw new Error('Invalid embedding response format');
        }
      } catch (err) {
        error = err instanceof Error ? err.message : 'Unknown embedding error';

        if (attempt < options.maxRetries) {
          // Wait before retrying
          await new Promise(resolve => setTimeout(resolve, options.retryDelay * (attempt + 1)));
        }
      }
    }

    results.push({ success, embedding, error });
  }

  return results;
}

/**
 * Calculates similarity between embeddings using cosine similarity
 */
export function calculateEmbeddingSimilarity(embedding1: number[], embedding2: number[]): number {
  if (embedding1.length !== embedding2.length) {
    throw new Error('Embeddings must have the same dimensions');
  }

  let dotProduct = 0;
  let norm1 = 0;
  let norm2 = 0;

  for (let i = 0; i < embedding1.length; i++) {
    dotProduct += embedding1[i] * embedding2[i];
    norm1 += embedding1[i] * embedding1[i];
    norm2 += embedding2[i] * embedding2[i];
  }

  norm1 = Math.sqrt(norm1);
  norm2 = Math.sqrt(norm2);

  if (norm1 === 0 || norm2 === 0) {
    return 0;
  }

  return dotProduct / (norm1 * norm2);
}

/**
 * Finds the most similar embeddings to a query embedding
 */
export function findSimilarEmbeddings(
  queryEmbedding: number[],
  embeddings: number[][],
  topK: number = 5
): Array<{ index: number; similarity: number }> {
  const similarities: Array<{ index: number; similarity: number }> = [];

  embeddings.forEach((embedding, index) => {
    if (embedding.length > 0) {
      const similarity = calculateEmbeddingSimilarity(queryEmbedding, embedding);
      similarities.push({ index, similarity });
    }
  });

  // Sort by similarity (descending)
  similarities.sort((a, b) => b.similarity - a.similarity);

  return similarities.slice(0, topK);
}

/**
 * Validates embedding quality and consistency
 */
export function validateEmbeddings(
  embeddings: number[][],
  expectedDimensions?: number
): { valid: boolean; errors: string[]; stats: { total: number; valid: number; avgDimensions: number } } {
  const errors: string[] = [];
  let validCount = 0;
  let totalDimensions = 0;

  embeddings.forEach((embedding, index) => {
    if (!Array.isArray(embedding)) {
      errors.push(`Embedding ${index}: not an array`);
      return;
    }

    if (embedding.length === 0) {
      errors.push(`Embedding ${index}: empty array`);
      return;
    }

    if (expectedDimensions && embedding.length !== expectedDimensions) {
      errors.push(`Embedding ${index}: expected ${expectedDimensions} dimensions, got ${embedding.length}`);
      return;
    }

    // Check for NaN or infinite values
    if (embedding.some(val => !isFinite(val))) {
      errors.push(`Embedding ${index}: contains NaN or infinite values`);
      return;
    }

    validCount++;
    totalDimensions += embedding.length;
  });

  const avgDimensions = validCount > 0 ? totalDimensions / validCount : 0;

  return {
    valid: errors.length === 0,
    errors,
    stats: {
      total: embeddings.length,
      valid: validCount,
      avgDimensions
    }
  };
}

/**
 * Reduces embedding dimensionality using simple averaging
 * This is a basic implementation - in practice, you'd use proper dimensionality reduction
 */
export function reduceEmbeddingDimensions(
  embeddings: number[][],
  targetDimensions: number
): number[][] {
  if (embeddings.length === 0 || !embeddings[0]) {
    return [];
  }

  const currentDimensions = embeddings[0].length;

  if (targetDimensions >= currentDimensions) {
    return embeddings;
  }

  // Simple dimensionality reduction by averaging chunks
  const chunkSize = Math.floor(currentDimensions / targetDimensions);

  return embeddings.map(embedding => {
    const reduced: number[] = [];

    for (let i = 0; i < targetDimensions; i++) {
      const start = i * chunkSize;
      const end = start + chunkSize;
      const chunk = embedding.slice(start, end);
      const average = chunk.reduce((sum, val) => sum + val, 0) / chunk.length;
      reduced.push(average);
    }

    return reduced;
  });
}
