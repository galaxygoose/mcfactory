// This file is generated by the Architect Agent.
// Other agents must implement logic INSIDE this file only.
// Do NOT create or delete files. Respect the MIC + MIM.

import {
  PipelineDefinition,
  PipelineResult,
  PipelineStep,
  FactoryOptions
} from '../../types';
import { Workflow } from './workflow';

export interface WorkflowRunnerOptions extends FactoryOptions {
  executionMode?: 'sequential' | 'parallel';
}

export class WorkflowRunner {
  static async run(
    pipeline: PipelineDefinition,
    initialData: any,
    options?: WorkflowRunnerOptions
  ): Promise<PipelineResult<any>> {
    const executionMode = options?.executionMode || 'sequential';

    if (executionMode === 'parallel') {
      return this.runParallel(pipeline, initialData, options);
    } else {
      return this.runSequential(pipeline, initialData, options);
    }
  }

  private static async runSequential(
    pipeline: PipelineDefinition,
    initialData: any,
    options?: WorkflowRunnerOptions
  ): Promise<PipelineResult<any>> {
    // Use the Workflow class for sequential execution
    return Workflow.execute(pipeline, initialData, options);
  }

  private static async runParallel(
    pipeline: PipelineDefinition,
    initialData: any,
    options?: WorkflowRunnerOptions
  ): Promise<PipelineResult<any>> {
    const logs: string[] = [];

    try {
      logs.push(`Starting parallel pipeline execution: ${pipeline.name}`);

      // For parallel execution, we need to handle steps that can run concurrently
      // Some steps might depend on each other, so we'll group independent steps
      const stepResults = await Promise.all(
        pipeline.steps.map(async (step, index) => {
          logs.push(`Executing parallel step ${index + 1}/${pipeline.steps.length}: ${step.type}`);
          try {
            const result = await this.executeParallelStep(step, initialData, options);
            logs.push(`Parallel step ${step.type} completed successfully`);
            return { step: step.type, result, success: true };
          } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error';
            logs.push(`Parallel step ${step.type} failed: ${errorMessage}`);
            return { step: step.type, result: null, success: false, error: errorMessage };
          }
        })
      );

      // Merge results from parallel execution
      const mergedData = this.mergeParallelResults(stepResults, initialData);
      const hasFailures = stepResults.some(r => !r.success);

      if (hasFailures) {
        logs.push('Some parallel steps failed, but continuing with merged results');
      }

      return {
        success: !hasFailures,
        data: mergedData,
        logs
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown parallel execution error';
      logs.push(`Parallel pipeline execution failed: ${errorMessage}`);

      return {
        success: false,
        data: null,
        logs
      };
    }
  }

  private static async executeParallelStep(
    step: PipelineStep,
    data: any,
    options?: WorkflowRunnerOptions
  ): Promise<any> {
    // For parallel execution, each step gets the same initial data
    // In a more sophisticated implementation, we might handle dependencies
    return Workflow['executeStep'](step, data, options, []);
  }

  private static mergeParallelResults(
    stepResults: Array<{ step: string; result: any; success: boolean; error?: string }>,
    initialData: any
  ): any {
    let mergedData = { ...initialData };

    // Merge successful results
    for (const stepResult of stepResults) {
      if (stepResult.success && stepResult.result !== undefined) {
        if (typeof stepResult.result === 'object' && stepResult.result !== null) {
          mergedData = { ...mergedData, ...stepResult.result };
        } else {
          mergedData[stepResult.step] = stepResult.result;
        }
      }
    }

    // Add failure information
    const failures = stepResults.filter(r => !r.success);
    if (failures.length > 0) {
      mergedData._parallelFailures = failures.map(f => ({ step: f.step, error: f.error }));
    }

    return mergedData;
  }
}
